{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
      "metadata": {
        "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f"
      },
      "source": [
        "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
        "- 이미지 binary 분류 과제\n",
        "- 담당: 이녕민M"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
      "metadata": {
        "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4325d39-6344-4116-b343-df51696905ec",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4325d39-6344-4116-b343-df51696905ec",
        "outputId": "00e84dbf-7bb3-4ea6-92b9-34e5d989856d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 43.1 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 83.7 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to ppa.launch\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,557 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,466 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [781 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,825 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [935 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [814 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,995 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,244 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 14.9 MB in 4s (4,141 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-nose python3-numpy-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 2,477 kB of archives.\n",
            "After this operation, 13.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 2,477 kB in 1s (3,046 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-opencv.\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y python3-opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f475804-13db-484c-a348-f01580e80a1e",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f475804-13db-484c-a348-f01580e80a1e",
        "outputId": "e6c2272b-71d0-4862-cba5-f62257092166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9siZY8S5uRIU",
        "outputId": "cd1c0d0e-95b0-4486-c6e6-9363cccc4d5f"
      },
      "id": "9siZY8S5uRIU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 10 08:22:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
      "metadata": {
        "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849d6aef-ec14-445e-a395-e6338b69f870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, torch, copy, cv2, sys, random\n",
        "# from datetime import datetime, timezone, timedelta\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from google.colab.patches import cv2_imshow \n",
        "import torchvision.transforms.functional as TF\n",
        "from imgaug import augmentables\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
      "metadata": {
        "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954"
      },
      "source": [
        "## Set Arguments & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
      "metadata": {
        "id": "8f9c4250-2257-404f-941d-58eff1e9eb38"
      },
      "outputs": [],
      "source": [
        "# 시드(seed) 설정\n",
        "\n",
        "RANDOM_SEED = 2022\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65",
      "metadata": {
        "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65"
      },
      "source": [
        "# 데이터 디렉토리 구조\n",
        "\n",
        "data/  \n",
        "  \\_train/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_test/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_train.csv  \n",
        "  \\_sample_submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
      "metadata": {
        "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "\n",
        "### 데이터 디렉토리 설정 ###\n",
        "DATA_DIR= '/content/drive/MyDrive/이어드림/project2/data'\n",
        "NUM_CLS = 2\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "INPUT_SHAPE = 128\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "DEVICE = torch.device('cuda')\n",
        "DATA_SIZE = 2000\n",
        "TRAIN_PER = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
      "metadata": {
        "id": "d44807b0-7788-49ec-aff2-c756e4513c5e"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
      "metadata": {
        "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05"
      },
      "source": [
        "#### Train & Validation Set loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -uq '/content/drive/MyDrive/이어드림/project2/test.zip' -d '/content/drive/MyDrive/이어드림/project2'\n",
        "# !unzip -uq '/content/drive/MyDrive/이어드림/project2/train.zip' -d '/content/drive/MyDrive/이어드림/project2'\n"
      ],
      "metadata": {
        "id": "g4dXCoAUlrZH"
      },
      "id": "g4dXCoAUlrZH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6It9wEWWPx0"
      },
      "id": "A6It9wEWWPx0"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "04642777-c2e0-439b-9692-f6c571a86521",
      "metadata": {
        "id": "04642777-c2e0-439b-9692-f6c571a86521"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode, input_shape, data_size, train_per):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.input_shape = input_shape\n",
        "        self.data_size = data_size\n",
        "        self.train_per = train_per\n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Dataset split\n",
        "        if self.mode == 'train':\n",
        "            self.db = self.db[:int((self.data_size) * (self.train_per))]\n",
        "        elif self.mode == 'val':\n",
        "            self.db = self.db[int((self.data_size) * (self.train_per)):int(self.data_size)]\n",
        "            self.db.reset_index(inplace=True)\n",
        "        else:\n",
        "            print(f'!!! Invalid split {self.mode}... !!!')\n",
        "            \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "        def dbplus(db):\n",
        "            augdb = db.copy()\n",
        "            for i in range(15):\n",
        "                if i == 0:\n",
        "                    augdb['file_name'] = db['file_name'].apply(lambda x : int(x[:-4]) + int('646'))\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : str(x) +'.png')\n",
        "                    db = pd.concat([db, augdb], ignore_index = True,axis=0)\n",
        "                else :\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : int(x[:-4]) + int('646'))\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : str(x) +'.png')\n",
        "                    db = pd.concat([db, augdb], ignore_index = True,axis=0)\n",
        "            return db\n",
        "        return dbplus(db)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == 'train':\n",
        "            return int(int(self.data_size)*(self.train_per))\n",
        "        elif self.mode == 'val':\n",
        "            return int(int(self.data_size) - (int(self.data_size)*(self.train_per)))\n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name+'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "         \n",
        "        return trans_image, data['COVID']\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #########Equalization visualization###################\n",
        "# import imgaug as ia\n",
        "\n",
        "# db = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "# data = copy.deepcopy(db.loc[7])\n",
        "# sss =cv2.imread(os.path.join(DATA_DIR,'train',data['file_name']), 0)\n",
        "# cv2_imshow(sss)\n",
        "# print(sss.shape)\n",
        "# augmentation_resize = iaa.Sequential([\n",
        "#                 iaa.Resize({\"height\":384,\"width\":384},interpolation=\"cubic\")\n",
        "#             ])\n",
        "\n",
        "\n",
        "# image_aug = augmentation_resize(image=sss)\n",
        "# cv2_imshow(image_aug)\n",
        "# # sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "# augmentation_resize = iaa.Sequential([\n",
        "#                     # iaa.Affine(translate_percent={\"x\":(-0.5,0.5),\"y\":(-0.5,0.5)},rotate=(-2,2),scale=(0.5,2)),\n",
        "#                     iaa.Crop(px=(0, 16)),\n",
        "#                     iaa.Multiply((0.8, 1.3)),\n",
        "#                     iaa.LinearContrast((1.5,2.3)),\n",
        "#                     # iaa.GaussianBlur((0.0,3.0)),\n",
        "#                     iaa.Fliplr(0.5),\n",
        "#                     iaa.Flipud(0.2),\n",
        "#                     iaa.Sharpen(alpha=(0, 1.0), lightness=(0.95, 1.5)),\n",
        "#                     iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0))])\n",
        "      \n",
        "                    \n",
        "# image_augs = augmentation_resize(image=image_aug)\n",
        "# cv2_imshow(image_augs)\n",
        "\n",
        "                    "
      ],
      "metadata": {
        "id": "y12HVh0uSFc_"
      },
      "id": "y12HVh0uSFc_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#augment시 사용\n",
        "eq_img_list = []\n",
        "class Augmentation:\n",
        "    def __init__(self, data_dir, mode, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.input_shape = input_shape\n",
        "        self.img = None\n",
        "    \n",
        "        #이미지크기 저장공간\n",
        "\n",
        "        self.db = self.data_loader()\n",
        "        if self.mode == 'train':\n",
        "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
        "        elif self.mode == 'val':\n",
        "            self.db = self.db[int(len(self.db) * 0.9):]\n",
        "            self.db.reset_index(inplace=True)\n",
        "        else:\n",
        "            print(f'!!! Invalid split {self.mode}... !!!')\n",
        "            \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "       \n",
        "        return db\n",
        "    def Equalization(self):\n",
        "    #    // for cnt in tqdm(range(646)):\n",
        "        for i in tqdm(range(646)):\n",
        "            # img = eq_img_list\n",
        "            db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "            data = copy.deepcopy(db.loc[i])\n",
        "            cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']))\n",
        "            cvimg_yuv = cv2.cvtColor(cvimg, cv2.COLOR_BGR2YUV)\n",
        "\n",
        "            img_clahe = cvimg_yuv.copy()\n",
        "            clahe = cv2.createCLAHE(clipLimit = 3.0 , tileGridSize=(8,8))\n",
        "            img_clahe[:,:,0] = clahe.apply(img_clahe[:,:,0])\n",
        "            img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "                # img_eq = cv2_imshow(img_clahe)\n",
        "            # cv2.waitKey()\n",
        "            cv2.destroyAllWindows()\n",
        "            eq_img_list.append(img_clahe)\n",
        "            # os.makedirs('/content/drive/MyDrive/이어드림/project2/data/aug_img', exist_ok=True)\n",
        "            cv2.imwrite(f'/content/drive/MyDrive/이어드림/project2/data/train/{i + 646}.png', img_clahe)\n",
        "            self.img = eq_img_list\n",
        "        return eq_img_list\n",
        "\n",
        "    def augmentation(self):\n",
        "        \n",
        "        for i in tqdm(range(646)):\n",
        "            \n",
        "            db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "            data = copy.deepcopy(db.loc[i])\n",
        "            sss =cv2.imread(os.path.join(self.data_dir,'train',data['file_name']))\n",
        "            \n",
        "            # cv2_imshow(sss)\n",
        "            augmentation_resize = iaa.Sequential([\n",
        "                            iaa.Resize({\"height\":384,\"width\":384},interpolation=\"cubic\")\n",
        "                        ])\n",
        "\n",
        "\n",
        "            image_aug = augmentation_resize(image=sss)\n",
        "            # cv2_imshow(image_aug)\n",
        "            # sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "            for j in (range(30)):\n",
        "                augmentation_resize = iaa.Sequential([\n",
        "                                    # iaa.Affine(translate_percent={\"x\":(-0.5,0.5),\"y\":(-0.5,0.5)},rotate=(-2,2),scale=(0.5,2)),\n",
        "                                    iaa.Crop(px=(0, 16)),\n",
        "                                    iaa.Multiply((0.8, 1.3)),\n",
        "                                    iaa.LinearContrast((1.5,2.3)),\n",
        "                                    # iaa.GaussianBlur((0.0,3.0)),\n",
        "                                    iaa.Fliplr(0.5),\n",
        "                                    iaa.Flipud(0.5),\n",
        "                                    iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}),\n",
        "                                    iaa.PerspectiveTransform(scale=(0.01, 0.15)),\n",
        "                                    iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
        "                                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.95, 1.5)),\n",
        "                                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0))])\n",
        "                    \n",
        "                image_augs = augmentation_resize(image=image_aug)\n",
        "            # cv2_imshow(image_augs)\n",
        "                # os.makedirs('/content/drive/MyDrive/이어드림/project2/data/augment{}'.format(j), exist_ok=True)\n",
        "                cv2.imwrite(f'/content/drive/MyDrive/이어드림/project2/data/train/{(i)+(1292)+(646*j)}.png', image_augs)\n"
      ],
      "metadata": {
        "id": "SJjYJ-LjGXCF"
      },
      "id": "SJjYJ-LjGXCF",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augm\n",
        "if __name__ == '__main__': \n",
        "    temp = Augmentation(DATA_DIR,'train', INPUT_SHAPE)\n",
        "    print('이미w지를 불러오는 중입니다.')\n",
        "    temp.data_loader()\n",
        "    print('*' * 30)\n",
        "    print('Equalization중 입니다')\n",
        "    #temp.Equalization()\n",
        "    print('*' * 30)\n",
        "    print('Equalization 성공')\n",
        "    print('Augmentation중 입니다')\n",
        "    temp.augmentation()\n",
        "\n",
        "    print('*' * 30)\n",
        "    del temp\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "Pyn67QEKHalG",
        "outputId": "cca182eb-11cb-4336-9228-984230f09532"
      },
      "id": "Pyn67QEKHalG",
      "execution_count": 47,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train dataset..\n",
            "이미w지를 불러오는 중입니다.\n",
            "Loading train dataset..\n",
            "******************************\n",
            "Equalization중 입니다\n",
            "******************************\n",
            "Equalization 성공\n",
            "Augmentation중 입니다\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 337/646 [46:10<42:20,  8.22s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ec335d13e9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Equalization 성공'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Augmentation중 입니다'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-0e47753384c8>\u001b[0m in \u001b[0;36maugmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# cv2_imshow(image_augs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# os.makedirs('/content/drive/MyDrive/이어드림/project2/data/augment{}'.format(j), exist_ok=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/이어드림/project2/data/train/{(i)+(1292)+(646*j)}.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_augs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
      "metadata": {
        "id": "61b27520-c82c-4ec8-ae0b-119a79167f09"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
      "metadata": {
        "id": "685e0b73-f323-40ea-b372-6c1d607618a9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class custom_CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(custom_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
        "        #self.Dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
        "        x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
        "        \n",
        "        x = torch.flatten(x,1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #x = self.Dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        \n",
        "        output = self.softmax(x)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d056905-1f77-4579-a260-07bb1056f6db",
      "metadata": {
        "id": "1d056905-1f77-4579-a260-07bb1056f6db"
      },
      "source": [
        "## Utils\n",
        "### EarlyStopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
      "metadata": {
        "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87"
      },
      "outputs": [],
      "source": [
        "class LossEarlyStopper():\n",
        "    \"\"\"Early stopper\n",
        "    \n",
        "    Attributes:\n",
        "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
        "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
        "        min_loss (float): 최소 loss\n",
        "        stop (bool): True 일 때 학습 중단\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience: int)-> None:\n",
        "        self.patience = patience\n",
        "\n",
        "        self.patience_counter = 0\n",
        "        self.min_loss = np.Inf\n",
        "        self.stop = False\n",
        "        self.save_model = False\n",
        "\n",
        "    def check_early_stopping(self, loss: float)-> None:\n",
        "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
        "\n",
        "        if self.min_loss == np.Inf:\n",
        "            self.min_loss = loss\n",
        "            return None\n",
        "\n",
        "        elif loss > self.min_loss:\n",
        "            self.patience_counter += 1\n",
        "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "            if self.patience_counter == self.patience:\n",
        "                self.stop = True\n",
        "                \n",
        "        elif loss <= self.min_loss:\n",
        "            self.patience_counter = 0\n",
        "            self.save_model = True\n",
        "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
        "            self.min_loss = loss\n",
        "        \n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
      "metadata": {
        "id": "1aaffd8d-b025-42c1-8dd8-69529487389e"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
      "metadata": {
        "id": "5faaac1b-64c3-4659-82de-d4309502f29a"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
        "    \n",
        "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
        "        \"\"\" 초기화\n",
        "        \"\"\"\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.metric_fn = metric_fn\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
        "        \n",
        "        self.model.train()\n",
        "        train_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            \n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            train_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.train_mean_loss = train_total_loss / batch_index\n",
        "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
        "        print(msg)\n",
        "\n",
        "    def validate_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            val_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.val_mean_loss = val_total_loss / batch_index\n",
        "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
      "metadata": {
        "id": "e2aca506-d168-4c9f-8eca-5cdecb122961"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
      "metadata": {
        "id": "33678d90-a254-48d5-bf09-2a817eeafea3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def get_metric_fn(y_pred, y_answer):\n",
        "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
        "    \n",
        "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
        "    accuracy = accuracy_score(y_answer, y_pred)\n",
        "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
      "metadata": {
        "tags": [],
        "id": "d729c079-9d85-49ce-857f-320b0c56a3a8"
      },
      "source": [
        "## Train\n",
        "### 학습을 위한 객체 선언"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
      "metadata": {
        "tags": [],
        "id": "b19610a4-ad7c-44a0-80cd-9734b5015100"
      },
      "source": [
        "#### Load Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
        "outputId": "2d0ba48d-2ad0-4e79-90f7-85c7e5b2115a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train dataset..\n",
            "Loading val dataset..\n",
            "Train set samples: 1400 Val set samples: 600\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE, data_size= DATA_SIZE, train_per = TRAIN_PER)\n",
        "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE, data_size = DATA_SIZE, train_per = TRAIN_PER)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDz5CyYnMitj",
        "outputId": "a7e6976c-a36a-48b9-ec17-e72116c4b090"
      },
      "id": "RDz5CyYnMitj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm \n",
        "#기본 사용시 0.766\n",
        "#efficientnet\n",
        "class Efficientnet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Efficientnet, self).__init__()\n",
        "        self.efficientnet = timm.create_model('efficientnetv2_s', pretrained=False, num_classes=num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.efficientnet(x)\n",
        "        \n",
        "        output = self.softmax(x)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "_DA_rB_EMhBw"
      },
      "id": "_DA_rB_EMhBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
      "metadata": {
        "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4"
      },
      "source": [
        "#### Load model and other utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
      "metadata": {
        "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = custom_CNN(NUM_CLS).to(DEVICE)\n",
        "\n",
        "# # Save Initial Model\n",
        "# torch.save(model.state_dict(), 'initial.pt')\n",
        "\n",
        "# Set optimizer, scheduler, loss function, metric function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
        "loss_fn = nn.BCELoss()\n",
        "metric_fn = get_metric_fn\n",
        "\n",
        "\n",
        "# Set trainer\n",
        "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
        "\n",
        "# Set earlystopper\n",
        "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
        "outputId": "4faaf87f-e7cd-418b-afec-6e7080c2b394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "custom_CNN(\n",
              "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 25, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=21025, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
      "metadata": {
        "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724"
      },
      "source": [
        "### epoch 단위 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
        "outputId": "47eec2ea-2744-4782-9771-9f36f32e90e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train loss: 0.6769338416498761, Acc: 0.5992857142857143, F1-Macro: 0.5896069287141905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/30 [00:17<08:26, 17.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Val loss: 0.6651052369011773, Acc: 0.655, F1-Macro: 0.6542999574137629\n",
            "Epoch 1, Train loss: 0.4904471781364707, Acc: 0.7692857142857142, F1-Macro: 0.768471940406869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [00:34<08:07, 17.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val loss: 1.3286901712417603, Acc: 0.5816666666666667, F1-Macro: 0.5322618215699977\n",
            "Early stopping counter 1/10\n",
            "Epoch 2, Train loss: 0.29281309853459514, Acc: 0.8907142857142857, F1-Macro: 0.8905064154959492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:52<07:51, 17.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Val loss: 1.0542037039995193, Acc: 0.6616666666666666, F1-Macro: 0.6505532906231799\n",
            "Early stopping counter 2/10\n",
            "Epoch 3, Train loss: 0.1364080626084361, Acc: 0.955, F1-Macro: 0.9549027878973808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [01:10<07:36, 17.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Val loss: 1.135621769560708, Acc: 0.72, F1-Macro: 0.7198879551820729\n",
            "Early stopping counter 3/10\n",
            "Epoch 4, Train loss: 0.05280398277479202, Acc: 0.9828571428571429, F1-Macro: 0.9828255980372113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [01:27<07:21, 17.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Val loss: 1.1454355435238943, Acc: 0.7116666666666667, F1-Macro: 0.7068384589531478\n",
            "Early stopping counter 4/10\n",
            "Epoch 5, Train loss: 0.02557325757346874, Acc: 0.9942857142857143, F1-Macro: 0.9942729862899383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [01:45<07:00, 17.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Val loss: 1.3228499905930624, Acc: 0.7166666666666667, F1-Macro: 0.7166162873399715\n",
            "Early stopping counter 5/10\n",
            "Epoch 6, Train loss: 0.008398695448196904, Acc: 0.9985714285714286, F1-Macro: 0.9985680503391675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [02:02<06:41, 17.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Val loss: 1.555917845831977, Acc: 0.7366666666666667, F1-Macro: 0.7363121530057077\n",
            "Early stopping counter 6/10\n",
            "Epoch 7, Train loss: 0.0014456597496592981, Acc: 1.0, F1-Macro: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [02:19<06:22, 17.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Val loss: 1.74022286468082, Acc: 0.735, F1-Macro: 0.7345391304347826\n",
            "Early stopping counter 7/10\n",
            "Epoch 8, Train loss: 0.000739247083994235, Acc: 1.0, F1-Macro: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [02:37<06:06, 17.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Val loss: 1.952772715025478, Acc: 0.7416666666666667, F1-Macro: 0.7412865015536719\n",
            "Early stopping counter 8/10\n",
            "Epoch 9, Train loss: 0.0005451430008898294, Acc: 1.0, F1-Macro: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [02:54<05:48, 17.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Val loss: 2.16565563943651, Acc: 0.7383333333333333, F1-Macro: 0.7381696893892016\n",
            "Early stopping counter 9/10\n",
            "Epoch 10, Train loss: 0.00044038678065272657, Acc: 1.0, F1-Macro: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [03:11<06:23, 19.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Val loss: 2.267538345522351, Acc: 0.7433333333333333, F1-Macro: 0.743047830923248\n",
            "Early stopping counter 10/10\n",
            "Early stopped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch_index in tqdm(range(EPOCHS)):\n",
        "\n",
        "    trainer.train_epoch(train_dataloader, epoch_index)\n",
        "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
        "\n",
        "    # early_stopping check\n",
        "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
        "\n",
        "    if early_stopper.stop:\n",
        "        print('Early stopped')\n",
        "        break\n",
        "\n",
        "    if early_stopper.save_model:\n",
        "        check_point = {\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        torch.save(check_point, 'best.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe53514a-e83f-4795-9589-640f26cc2993",
      "metadata": {
        "id": "fe53514a-e83f-4795-9589-640f26cc2993"
      },
      "source": [
        "## Inference\n",
        "### 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
      "metadata": {
        "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3"
      },
      "outputs": [],
      "source": [
        "TRAINED_MODEL_PATH = 'best.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wZ8tBJ4wavx7"
      },
      "id": "wZ8tBJ4wavx7"
    },
    {
      "cell_type": "markdown",
      "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
      "metadata": {
        "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
      "metadata": {
        "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_dir, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading test dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
        "        return db\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        \n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "        return trans_image, data['file_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
        "outputId": "0586e9da-12f5-420a-b250-6ec8790dda55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset..\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
      "metadata": {
        "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58"
      },
      "source": [
        "### 추론 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
        "outputId": "d65a8add-9fce-45bd-d5e0-56e79482d1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.3233e-01, 6.6767e-01],\n",
            "        [9.8640e-01, 1.3602e-02],\n",
            "        [9.9258e-01, 7.4226e-03],\n",
            "        [1.8353e-04, 9.9982e-01],\n",
            "        [7.7023e-01, 2.2977e-01],\n",
            "        [2.8520e-03, 9.9715e-01],\n",
            "        [2.1277e-03, 9.9787e-01],\n",
            "        [7.7942e-02, 9.2206e-01],\n",
            "        [1.0000e+00, 3.7712e-07],\n",
            "        [5.3618e-07, 1.0000e+00],\n",
            "        [6.0757e-01, 3.9243e-01],\n",
            "        [8.5285e-01, 1.4715e-01],\n",
            "        [9.7628e-02, 9.0237e-01],\n",
            "        [1.0000e+00, 5.1732e-08],\n",
            "        [9.9976e-01, 2.4376e-04],\n",
            "        [9.9583e-01, 4.1667e-03],\n",
            "        [7.2966e-01, 2.7034e-01],\n",
            "        [1.0000e+00, 4.0393e-06],\n",
            "        [9.9765e-01, 2.3540e-03],\n",
            "        [9.9606e-01, 3.9383e-03],\n",
            "        [1.0000e+00, 2.9629e-07],\n",
            "        [9.9657e-01, 3.4350e-03],\n",
            "        [9.7694e-01, 2.3063e-02],\n",
            "        [1.8252e-01, 8.1748e-01],\n",
            "        [1.0000e+00, 1.5197e-06],\n",
            "        [1.0000e+00, 6.7776e-07],\n",
            "        [1.0000e+00, 1.6590e-07],\n",
            "        [9.9968e-01, 3.2456e-04],\n",
            "        [1.0541e-05, 9.9999e-01],\n",
            "        [2.8501e-01, 7.1499e-01],\n",
            "        [9.9999e-01, 1.2622e-05],\n",
            "        [5.6005e-03, 9.9440e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8.9685e-01, 1.0315e-01],\n",
            "        [3.1713e-01, 6.8287e-01],\n",
            "        [9.9967e-01, 3.2719e-04],\n",
            "        [1.1149e-01, 8.8851e-01],\n",
            "        [9.9997e-01, 3.1127e-05],\n",
            "        [6.9143e-03, 9.9309e-01],\n",
            "        [1.0195e-01, 8.9805e-01],\n",
            "        [2.3974e-01, 7.6026e-01],\n",
            "        [1.5435e-05, 9.9998e-01],\n",
            "        [4.2047e-02, 9.5795e-01],\n",
            "        [6.6023e-01, 3.3977e-01],\n",
            "        [6.5953e-03, 9.9340e-01],\n",
            "        [9.6547e-01, 3.4534e-02],\n",
            "        [5.8866e-06, 9.9999e-01],\n",
            "        [9.4982e-01, 5.0181e-02],\n",
            "        [9.9903e-01, 9.7241e-04],\n",
            "        [3.0732e-01, 6.9268e-01],\n",
            "        [9.4565e-01, 5.4353e-02],\n",
            "        [4.5446e-02, 9.5455e-01],\n",
            "        [9.4744e-03, 9.9053e-01],\n",
            "        [8.8497e-01, 1.1503e-01],\n",
            "        [8.7558e-01, 1.2442e-01],\n",
            "        [5.0508e-05, 9.9995e-01],\n",
            "        [9.9999e-01, 1.0541e-05],\n",
            "        [9.1329e-01, 8.6715e-02],\n",
            "        [5.4124e-04, 9.9946e-01],\n",
            "        [6.6639e-01, 3.3361e-01],\n",
            "        [2.7223e-01, 7.2777e-01],\n",
            "        [5.2676e-01, 4.7324e-01],\n",
            "        [9.9999e-01, 5.8069e-06],\n",
            "        [1.0000e+00, 5.8435e-10],\n",
            "        [9.9999e-01, 8.6600e-06]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:00,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.1087e-05, 9.9999e-01],\n",
            "        [4.7387e-07, 1.0000e+00],\n",
            "        [7.2529e-05, 9.9993e-01],\n",
            "        [9.9995e-01, 4.6430e-05],\n",
            "        [1.5408e-05, 9.9998e-01],\n",
            "        [9.6515e-01, 3.4854e-02],\n",
            "        [9.9909e-01, 9.0870e-04],\n",
            "        [9.9963e-01, 3.7265e-04],\n",
            "        [9.9999e-01, 6.9930e-06],\n",
            "        [9.9973e-01, 2.6667e-04],\n",
            "        [1.6080e-10, 1.0000e+00],\n",
            "        [9.9923e-01, 7.7173e-04],\n",
            "        [1.0000e+00, 5.5726e-07],\n",
            "        [8.2528e-01, 1.7472e-01],\n",
            "        [4.7087e-01, 5.2913e-01],\n",
            "        [1.3722e-01, 8.6278e-01],\n",
            "        [1.0981e-07, 1.0000e+00],\n",
            "        [5.3858e-01, 4.6142e-01],\n",
            "        [5.8648e-01, 4.1352e-01],\n",
            "        [2.6292e-01, 7.3708e-01],\n",
            "        [1.0552e-01, 8.9448e-01],\n",
            "        [9.9996e-01, 3.6144e-05],\n",
            "        [9.9969e-01, 3.1389e-04],\n",
            "        [9.9978e-01, 2.2202e-04],\n",
            "        [6.1438e-01, 3.8562e-01],\n",
            "        [9.9913e-01, 8.6834e-04],\n",
            "        [9.9999e-01, 8.5097e-06],\n",
            "        [9.3646e-01, 6.3544e-02],\n",
            "        [9.9921e-01, 7.8874e-04],\n",
            "        [1.3774e-06, 1.0000e+00],\n",
            "        [9.4993e-01, 5.0066e-02],\n",
            "        [3.4472e-01, 6.5528e-01]], device='cuda:0')\n",
            "tensor([[2.7654e-01, 7.2346e-01],\n",
            "        [4.9553e-03, 9.9504e-01],\n",
            "        [9.9998e-01, 2.4727e-05],\n",
            "        [1.0410e-02, 9.8959e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
        "\n",
        "# Prediction\n",
        "file_lst = []\n",
        "pred_lst = []\n",
        "prob_lst = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
        "        img = img.to(DEVICE)\n",
        "        pred = model(img)\n",
        "        print(pred)\n",
        "        file_lst.extend(list(file_num))\n",
        "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "        prob_lst.extend(pred[:, 1].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
      "metadata": {
        "id": "056169d1-64a8-4b81-8daf-722b029cf2b9"
      },
      "source": [
        "### 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
      "metadata": {
        "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
        "# df.sort_values(by=['file_name'], inplace=True)\n",
        "df.to_csv(DATA_DIR+'/prediction(size3000,7:3).csv', index=False)\n",
        "#과적합줄이기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JBVoxgKKZKKO"
      },
      "id": "JBVoxgKKZKKO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
      "metadata": {
        "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Baseline ++ 가로",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}